{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successful!\n",
      "\n",
      "Data pre-processing successful!\n"
     ]
    }
   ],
   "source": [
    "#general:       \n",
    "import pandas as pd     \n",
    "import numpy as np  \n",
    "\n",
    "#for text preprocessing\n",
    "import preprocessor as p\n",
    "import re\n",
    "\n",
    "#Import data (read csv files)\n",
    "dfBitcoin = pd.read_csv('Hasitha_Raw_data/bitcoin.csv', nrows=60000)\n",
    "dfEthereum = pd.read_csv('Hasitha_Raw_data/ethereum.csv', nrows=60000)\n",
    "\n",
    "print(\"Data imported successful!\")\n",
    "\n",
    "\n",
    "#data pre-processing\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", p.clean(tweet)).split())\n",
    "\n",
    "#create a column with the result of the analysis:\n",
    "dfBitcoin['clean_text'] = np.array([ clean_tweet(tweet) for tweet in dfBitcoin['tweet_text'] ])\n",
    "dfEthereum['clean_text'] = np.array([ clean_tweet(tweet) for tweet in dfEthereum['tweet_text'] ])\n",
    "\n",
    "#Export data\n",
    "dfBitcoin.to_csv('Hasitha_Pre_Processed_Data/bitcoin_preprocessed_data.csv')\n",
    "dfEthereum.to_csv('Hasitha_Pre_Processed_Data/ethereum_preprocessed_data.csv')\n",
    "\n",
    "print('\\nData pre-processing successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy           \n",
    "import pandas as pd     \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "import re\n",
    "\n",
    "from preprocessor.api import clean, tokenize, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/raw/extracted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_created_time</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>twitter_source</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>tweet_retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245344129271431168</td>\n",
       "      <td>2020-04-01 13:35:52</td>\n",
       "      <td>b'@Enactus_Canada #stayathome Chinese https://...</td>\n",
       "      <td>59</td>\n",
       "      <td>2019-08-15 10:45:03</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245344126217990145</td>\n",
       "      <td>2020-04-01 13:35:51</td>\n",
       "      <td>b'@ArtCampOfficial #StayAtHome mate. No joke i...</td>\n",
       "      <td>74</td>\n",
       "      <td>2012-09-07 00:52:20</td>\n",
       "      <td>159</td>\n",
       "      <td>244</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245344091526836225</td>\n",
       "      <td>2020-04-01 13:35:43</td>\n",
       "      <td>b'\"Into this house we\\'re born\\nInto this worl...</td>\n",
       "      <td>140</td>\n",
       "      <td>2019-05-28 11:15:33</td>\n",
       "      <td>942</td>\n",
       "      <td>1776</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245344074636369921</td>\n",
       "      <td>2020-04-01 13:35:39</td>\n",
       "      <td>b'@LiveKellyRyan My grandson is over this stay...</td>\n",
       "      <td>94</td>\n",
       "      <td>2011-03-08 03:59:15</td>\n",
       "      <td>36</td>\n",
       "      <td>88</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245344074112139264</td>\n",
       "      <td>2020-04-01 13:35:39</td>\n",
       "      <td>b'On his birthday #Rachmaninoff #\\xd0\\xa0\\xd0\\...</td>\n",
       "      <td>119</td>\n",
       "      <td>2015-11-19 13:26:25</td>\n",
       "      <td>420</td>\n",
       "      <td>930</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id   tweet_created_time  \\\n",
       "0  1245344129271431168  2020-04-01 13:35:52   \n",
       "1  1245344126217990145  2020-04-01 13:35:51   \n",
       "2  1245344091526836225  2020-04-01 13:35:43   \n",
       "3  1245344074636369921  2020-04-01 13:35:39   \n",
       "4  1245344074112139264  2020-04-01 13:35:39   \n",
       "\n",
       "                                          tweet_text  tweet_length  \\\n",
       "0  b'@Enactus_Canada #stayathome Chinese https://...            59   \n",
       "1  b'@ArtCampOfficial #StayAtHome mate. No joke i...            74   \n",
       "2  b'\"Into this house we\\'re born\\nInto this worl...           140   \n",
       "3  b'@LiveKellyRyan My grandson is over this stay...            94   \n",
       "4  b'On his birthday #Rachmaninoff #\\xd0\\xa0\\xd0\\...           119   \n",
       "\n",
       "       user_created_at  user_followers_count  user_friends_count  \\\n",
       "0  2019-08-15 10:45:03                     7                  60   \n",
       "1  2012-09-07 00:52:20                   159                 244   \n",
       "2  2019-05-28 11:15:33                   942                1776   \n",
       "3  2011-03-08 03:59:15                    36                  88   \n",
       "4  2015-11-19 13:26:25                   420                 930   \n",
       "\n",
       "        twitter_source  tweet_likes  tweet_retweets  \n",
       "0      Twitter Web App            0               0  \n",
       "1      Twitter Web App            0               0  \n",
       "2  Twitter for Android            0               0  \n",
       "3   Twitter for iPhone            0               0  \n",
       "4   Twitter for iPhone            0               0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to clean the text in a tweet by removing links and special characters using regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", p.clean(tweet)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'preprocessor' has no attribute 'clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-a27f7669675b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-a27f7669675b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-aef10726e5c6>\u001b[0m in \u001b[0;36mclean_tweet\u001b[1;34m(tweet)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'preprocessor' has no attribute 'clean'"
     ]
    }
   ],
   "source": [
    "raw_data['clean_text'] = np.array([ clean_tweet(tweet) for tweet in raw_data['tweet_text'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-eedf950b62c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#removing stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mfiltered_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "tweet = raw_data['tweet_text']\n",
    "t=str(tweet)\n",
    "tt=t.lower()\n",
    "\n",
    "#removing urls(http:..)\n",
    "twt = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', tt)\n",
    "\n",
    "#removing any other punctuation or unwanted character\n",
    "tw=re.sub(r\"[.,;:$&*|?'-]\",'',twt)\n",
    "\n",
    "\n",
    "#removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(tw)\n",
    "filtered_sentence = [w.lower() for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "#changes the tweet back into a string\n",
    "final_tweet='  '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv('data/processed/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
